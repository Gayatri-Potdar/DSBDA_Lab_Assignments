{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCsT2vDxB16jSE2qfMjOSG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SmpnHE8PLL3Y","executionInfo":{"status":"ok","timestamp":1745689289838,"user_tz":-330,"elapsed":149,"user":{"displayName":"Disha Gawade","userId":"08413590762686857076"}},"outputId":"16e2b34d-631b-4cd7-9fb3-49d4fa7dc858"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset downloaded and saved as 'iris.csv'.\n","Dataset Overview:\n","   sepal_length  sepal_width  petal_length  petal_width species\n","0           5.1          3.5           1.4          0.2  setosa\n","1           4.9          3.0           1.4          0.2  setosa\n","2           4.7          3.2           1.3          0.2  setosa\n","3           4.6          3.1           1.5          0.2  setosa\n","4           5.0          3.6           1.4          0.2  setosa\n","\n","Confusion Matrix:\n","[[10  0  0]\n"," [ 0  9  0]\n"," [ 0  0 11]]\n","\n","Metrics:\n","True Positives (TP): [10  9 11]\n","False Positives (FP): [0 0 0]\n","True Negatives (TN): [20 21 19]\n","False Negatives (FN): [0 0 0]\n","Accuracy: 1.00\n","Error Rate: 0.00\n","Precision: 1.00\n","Recall: 1.00\n"]}],"source":["# 6) Data Analytics III\n","# 1. Implement Simple Naïve Bayes classification algorithm using Python/R on iris.csv dataset.\n","# 2. Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall on\n","# the given dataset.\n","\n","import pandas as pd\n","\n","# URL of the dataset\n","url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n","\n","# Load the dataset into a DataFrame\n","df = pd.read_csv(url)\n","\n","# Save the dataset locally\n","df.to_csv(\"iris.csv\", index=False)\n","\n","print(\"Dataset downloaded and saved as 'iris.csv'.\")\n","\n","# Import required libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n","\n","# Load the Iris dataset\n","df = pd.read_csv(\"iris.csv\")  # Ensure 'iris.csv' is in the same directory\n","\n","# Display the first few rows of the dataset\n","print(\"Dataset Overview:\")\n","print(df.head())\n","\n","# Prepare the features (X) and the target variable (y)\n","X = df.drop(columns=[\"species\"])  # Features: Sepal & Petal measurements\n","y = df[\"species\"]                # Target: Species\n","\n","# Split the dataset into training and testing sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train the Naïve Bayes classifier\n","nb_classifier = GaussianNB()\n","nb_classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test dataset\n","y_pred = nb_classifier.predict(X_test)\n","\n","# Generate the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred, labels=y.unique())\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","\n","# Calculate True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN)\n","tp = conf_matrix.diagonal()  # True Positives: Diagonal elements\n","fp = conf_matrix.sum(axis=0) - tp  # False Positives: Column sum - TP\n","fn = conf_matrix.sum(axis=1) - tp  # False Negatives: Row sum - TP\n","tn = conf_matrix.sum() - (tp + fp + fn)  # True Negatives: Total sum - (TP + FP + FN)\n","\n","# Calculate metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","error_rate = 1 - accuracy\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","\n","# Display the computed metrics\n","print(\"\\nMetrics:\")\n","print(f\"True Positives (TP): {tp}\")\n","print(f\"False Positives (FP): {fp}\")\n","print(f\"True Negatives (TN): {tn}\")\n","print(f\"False Negatives (FN): {fn}\")\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(f\"Error Rate: {error_rate:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n"]},{"cell_type":"markdown","source":["📚 THEORY (In Short)\n","1. Naïve Bayes Classifier\n","A simple probabilistic classifier based on Bayes' Theorem.\n","\n","It assumes that features are independent of each other (\"naïve\" assumption).\n","\n","Formula:\n","\n","𝑃\n","(\n","𝐶\n","𝑙\n","𝑎\n","𝑠\n","𝑠\n","∣\n","𝐹\n","𝑒\n","𝑎\n","𝑡\n","𝑢\n","𝑟\n","𝑒\n","𝑠\n",")\n","=\n","𝑃\n","(\n","𝐹\n","𝑒\n","𝑎\n","𝑡\n","𝑢\n","𝑟\n","𝑒\n","𝑠\n","∣\n","𝐶\n","𝑙\n","𝑎\n","𝑠\n","𝑠\n",")\n","×\n","𝑃\n","(\n","𝐶\n","𝑙\n","𝑎\n","𝑠\n","𝑠\n",")\n","𝑃\n","(\n","𝐹\n","𝑒\n","𝑎\n","𝑡\n","𝑢\n","𝑟\n","𝑒\n","𝑠\n",")\n","P(Class∣Features)=\n","P(Features)\n","P(Features∣Class)×P(Class)\n","​\n","\n","In simple words, it predicts the class that has the highest probability given the input features.\n","\n","2. Gaussian Naïve Bayes\n","Gaussian because it assumes the data is normally distributed.\n","\n","Suitable for continuous features like sepal length, petal length, etc.\n","\n","3. Confusion Matrix\n","It shows how well the model performed:\n","\n","\n","Predicted Positive\tPredicted Negative\n","Actual Positive\tTrue Positive (TP)\tFalse Negative (FN)\n","Actual Negative\tFalse Positive (FP)\tTrue Negative (TN)\n","TP = Correctly predicted positive.\n","\n","TN = Correctly predicted negative.\n","\n","FP = Wrongly predicted positive.\n","\n","FN = Wrongly predicted negative.\n","\n","4. Metrics Formulas\n","Accuracy =\n","𝑇\n","𝑃\n","+\n","𝑇\n","𝑁\n","𝑇\n","𝑃\n","+\n","𝐹\n","𝑃\n","+\n","𝐹\n","𝑁\n","+\n","𝑇\n","𝑁\n","TP+FP+FN+TN\n","TP+TN\n","​\n","\n","\n","Error Rate =\n","1\n","−\n","𝐴\n","𝑐\n","𝑐\n","𝑢\n","𝑟\n","𝑎\n","𝑐\n","𝑦\n","1−Accuracy\n","\n","Precision =\n","𝑇\n","𝑃\n","𝑇\n","𝑃\n","+\n","𝐹\n","𝑃\n","TP+FP\n","TP\n","​\n","\n","(How many selected are relevant?)\n","\n","Recall =\n","𝑇\n","𝑃\n","𝑇\n","𝑃\n","+\n","𝐹\n","𝑁\n","TP+FN\n","TP\n","​\n","\n","(How many relevant were selected?)\n","\n","🧠 CODE EXPLANATION (Line by Line)\n","Step 1: Import Libraries\n","python\n","Copy\n","Edit\n","import pandas as pd\n","Import Pandas for data manipulation (handling CSV files, dataframes).\n","\n","Step 2: Download and Save Dataset\n","python\n","Copy\n","Edit\n","url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n","df = pd.read_csv(url)\n","df.to_csv(\"iris.csv\", index=False)\n","print(\"Dataset downloaded and saved as 'iris.csv'.\")\n","Download Iris dataset from URL.\n","\n","Save it locally as iris.csv.\n","\n","Print confirmation message.\n","\n","Step 3: More Imports\n","python\n","Copy\n","Edit\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n","Import:\n","\n","train_test_split: To split data into train/test.\n","\n","GaussianNB: For Naïve Bayes model.\n","\n","Metrics: For evaluating performance (confusion matrix, accuracy, precision, recall).\n","\n","Step 4: Load Dataset\n","python\n","Copy\n","Edit\n","df = pd.read_csv(\"iris.csv\")\n","print(\"Dataset Overview:\")\n","print(df.head())\n","Load the saved iris.csv.\n","\n","Show the first 5 rows to understand the data.\n","\n","Step 5: Prepare Features and Target\n","python\n","Copy\n","Edit\n","X = df.drop(columns=[\"species\"])  \n","y = df[\"species\"]\n","X = Input features (sepal and petal measurements).\n","\n","y = Target label (species name).\n","\n","Step 6: Split Data into Train and Test\n","python\n","Copy\n","Edit\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","80% data for training, 20% data for testing.\n","\n","random_state=42 ensures same split every time (for reproducibility).\n","\n","Step 7: Train the Model\n","python\n","Copy\n","Edit\n","nb_classifier = GaussianNB()\n","nb_classifier.fit(X_train, y_train)\n","Create a Gaussian Naïve Bayes object.\n","\n","Train (fit) it on training data.\n","\n","Step 8: Make Predictions\n","python\n","Copy\n","Edit\n","y_pred = nb_classifier.predict(X_test)\n","Predict the species on the test data.\n","\n","Step 9: Confusion Matrix\n","python\n","Copy\n","Edit\n","conf_matrix = confusion_matrix(y_test, y_pred, labels=y.unique())\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","Generate a confusion matrix comparing actual (y_test) vs predicted (y_pred).\n","\n","Print the confusion matrix.\n","\n","Step 10: Calculate TP, FP, TN, FN\n","python\n","Copy\n","Edit\n","tp = conf_matrix.diagonal()\n","fp = conf_matrix.sum(axis=0) - tp\n","fn = conf_matrix.sum(axis=1) - tp\n","tn = conf_matrix.sum() - (tp + fp + fn)\n","TP = Diagonal elements.\n","\n","FP = Column sums - TP.\n","\n","FN = Row sums - TP.\n","\n","TN = Total samples - (TP + FP + FN).\n","\n","Step 11: Calculate Metrics\n","python\n","Copy\n","Edit\n","accuracy = accuracy_score(y_test, y_pred)\n","error_rate = 1 - accuracy\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","Accuracy: How many total predictions were correct.\n","\n","Error Rate: How many were wrong.\n","\n","Precision: How many predicted positives are actually positive.\n","\n","Recall: How many actual positives are correctly predicted.\n","\n","Step 12: Print Results\n","python\n","Copy\n","Edit\n","print(\"\\nMetrics:\")\n","print(f\"True Positives (TP): {tp}\")\n","print(f\"False Positives (FP): {fp}\")\n","print(f\"True Negatives (TN): {tn}\")\n","print(f\"False Negatives (FN): {fn}\")\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(f\"Error Rate: {error_rate:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","Display all calculated values neatly.\n","\n","🎯 FINAL RESULT\n","By running this code:\n","\n","You trained a simple Naïve Bayes model on Iris data.\n","\n","You evaluated the model using confusion matrix and computed:\n","\n","TP, FP, TN, FN, Accuracy, Error Rate, Precision, Recall."],"metadata":{"id":"CyCCMhL1rKbt"}}]}