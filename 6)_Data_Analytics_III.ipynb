{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCsT2vDxB16jSE2qfMjOSG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SmpnHE8PLL3Y","executionInfo":{"status":"ok","timestamp":1745689289838,"user_tz":-330,"elapsed":149,"user":{"displayName":"Disha Gawade","userId":"08413590762686857076"}},"outputId":"16e2b34d-631b-4cd7-9fb3-49d4fa7dc858"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset downloaded and saved as 'iris.csv'.\n","Dataset Overview:\n","   sepal_length  sepal_width  petal_length  petal_width species\n","0           5.1          3.5           1.4          0.2  setosa\n","1           4.9          3.0           1.4          0.2  setosa\n","2           4.7          3.2           1.3          0.2  setosa\n","3           4.6          3.1           1.5          0.2  setosa\n","4           5.0          3.6           1.4          0.2  setosa\n","\n","Confusion Matrix:\n","[[10  0  0]\n"," [ 0  9  0]\n"," [ 0  0 11]]\n","\n","Metrics:\n","True Positives (TP): [10  9 11]\n","False Positives (FP): [0 0 0]\n","True Negatives (TN): [20 21 19]\n","False Negatives (FN): [0 0 0]\n","Accuracy: 1.00\n","Error Rate: 0.00\n","Precision: 1.00\n","Recall: 1.00\n"]}],"source":["# 6) Data Analytics III\n","# 1. Implement Simple NaÃ¯ve Bayes classification algorithm using Python/R on iris.csv dataset.\n","# 2. Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall on\n","# the given dataset.\n","\n","import pandas as pd\n","\n","# URL of the dataset\n","url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n","\n","# Load the dataset into a DataFrame\n","df = pd.read_csv(url)\n","\n","# Save the dataset locally\n","df.to_csv(\"iris.csv\", index=False)\n","\n","print(\"Dataset downloaded and saved as 'iris.csv'.\")\n","\n","# Import required libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n","\n","# Load the Iris dataset\n","df = pd.read_csv(\"iris.csv\")  # Ensure 'iris.csv' is in the same directory\n","\n","# Display the first few rows of the dataset\n","print(\"Dataset Overview:\")\n","print(df.head())\n","\n","# Prepare the features (X) and the target variable (y)\n","X = df.drop(columns=[\"species\"])  # Features: Sepal & Petal measurements\n","y = df[\"species\"]                # Target: Species\n","\n","# Split the dataset into training and testing sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train the NaÃ¯ve Bayes classifier\n","nb_classifier = GaussianNB()\n","nb_classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test dataset\n","y_pred = nb_classifier.predict(X_test)\n","\n","# Generate the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred, labels=y.unique())\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","\n","# Calculate True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN)\n","tp = conf_matrix.diagonal()  # True Positives: Diagonal elements\n","fp = conf_matrix.sum(axis=0) - tp  # False Positives: Column sum - TP\n","fn = conf_matrix.sum(axis=1) - tp  # False Negatives: Row sum - TP\n","tn = conf_matrix.sum() - (tp + fp + fn)  # True Negatives: Total sum - (TP + FP + FN)\n","\n","# Calculate metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","error_rate = 1 - accuracy\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","\n","# Display the computed metrics\n","print(\"\\nMetrics:\")\n","print(f\"True Positives (TP): {tp}\")\n","print(f\"False Positives (FP): {fp}\")\n","print(f\"True Negatives (TN): {tn}\")\n","print(f\"False Negatives (FN): {fn}\")\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(f\"Error Rate: {error_rate:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n"]},{"cell_type":"markdown","source":["ğŸ“š THEORY (In Short)\n","1. NaÃ¯ve Bayes Classifier\n","A simple probabilistic classifier based on Bayes' Theorem.\n","\n","It assumes that features are independent of each other (\"naÃ¯ve\" assumption).\n","\n","Formula:\n","\n","ğ‘ƒ\n","(\n","ğ¶\n","ğ‘™\n","ğ‘\n","ğ‘ \n","ğ‘ \n","âˆ£\n","ğ¹\n","ğ‘’\n","ğ‘\n","ğ‘¡\n","ğ‘¢\n","ğ‘Ÿ\n","ğ‘’\n","ğ‘ \n",")\n","=\n","ğ‘ƒ\n","(\n","ğ¹\n","ğ‘’\n","ğ‘\n","ğ‘¡\n","ğ‘¢\n","ğ‘Ÿ\n","ğ‘’\n","ğ‘ \n","âˆ£\n","ğ¶\n","ğ‘™\n","ğ‘\n","ğ‘ \n","ğ‘ \n",")\n","Ã—\n","ğ‘ƒ\n","(\n","ğ¶\n","ğ‘™\n","ğ‘\n","ğ‘ \n","ğ‘ \n",")\n","ğ‘ƒ\n","(\n","ğ¹\n","ğ‘’\n","ğ‘\n","ğ‘¡\n","ğ‘¢\n","ğ‘Ÿ\n","ğ‘’\n","ğ‘ \n",")\n","P(Classâˆ£Features)=\n","P(Features)\n","P(Featuresâˆ£Class)Ã—P(Class)\n","â€‹\n","\n","In simple words, it predicts the class that has the highest probability given the input features.\n","\n","2. Gaussian NaÃ¯ve Bayes\n","Gaussian because it assumes the data is normally distributed.\n","\n","Suitable for continuous features like sepal length, petal length, etc.\n","\n","3. Confusion Matrix\n","It shows how well the model performed:\n","\n","\n","Predicted Positive\tPredicted Negative\n","Actual Positive\tTrue Positive (TP)\tFalse Negative (FN)\n","Actual Negative\tFalse Positive (FP)\tTrue Negative (TN)\n","TP = Correctly predicted positive.\n","\n","TN = Correctly predicted negative.\n","\n","FP = Wrongly predicted positive.\n","\n","FN = Wrongly predicted negative.\n","\n","4. Metrics Formulas\n","Accuracy =\n","ğ‘‡\n","ğ‘ƒ\n","+\n","ğ‘‡\n","ğ‘\n","ğ‘‡\n","ğ‘ƒ\n","+\n","ğ¹\n","ğ‘ƒ\n","+\n","ğ¹\n","ğ‘\n","+\n","ğ‘‡\n","ğ‘\n","TP+FP+FN+TN\n","TP+TN\n","â€‹\n","\n","\n","Error Rate =\n","1\n","âˆ’\n","ğ´\n","ğ‘\n","ğ‘\n","ğ‘¢\n","ğ‘Ÿ\n","ğ‘\n","ğ‘\n","ğ‘¦\n","1âˆ’Accuracy\n","\n","Precision =\n","ğ‘‡\n","ğ‘ƒ\n","ğ‘‡\n","ğ‘ƒ\n","+\n","ğ¹\n","ğ‘ƒ\n","TP+FP\n","TP\n","â€‹\n","\n","(How many selected are relevant?)\n","\n","Recall =\n","ğ‘‡\n","ğ‘ƒ\n","ğ‘‡\n","ğ‘ƒ\n","+\n","ğ¹\n","ğ‘\n","TP+FN\n","TP\n","â€‹\n","\n","(How many relevant were selected?)\n","\n","ğŸ§  CODE EXPLANATION (Line by Line)\n","Step 1: Import Libraries\n","python\n","Copy\n","Edit\n","import pandas as pd\n","Import Pandas for data manipulation (handling CSV files, dataframes).\n","\n","Step 2: Download and Save Dataset\n","python\n","Copy\n","Edit\n","url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n","df = pd.read_csv(url)\n","df.to_csv(\"iris.csv\", index=False)\n","print(\"Dataset downloaded and saved as 'iris.csv'.\")\n","Download Iris dataset from URL.\n","\n","Save it locally as iris.csv.\n","\n","Print confirmation message.\n","\n","Step 3: More Imports\n","python\n","Copy\n","Edit\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n","Import:\n","\n","train_test_split: To split data into train/test.\n","\n","GaussianNB: For NaÃ¯ve Bayes model.\n","\n","Metrics: For evaluating performance (confusion matrix, accuracy, precision, recall).\n","\n","Step 4: Load Dataset\n","python\n","Copy\n","Edit\n","df = pd.read_csv(\"iris.csv\")\n","print(\"Dataset Overview:\")\n","print(df.head())\n","Load the saved iris.csv.\n","\n","Show the first 5 rows to understand the data.\n","\n","Step 5: Prepare Features and Target\n","python\n","Copy\n","Edit\n","X = df.drop(columns=[\"species\"])  \n","y = df[\"species\"]\n","X = Input features (sepal and petal measurements).\n","\n","y = Target label (species name).\n","\n","Step 6: Split Data into Train and Test\n","python\n","Copy\n","Edit\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","80% data for training, 20% data for testing.\n","\n","random_state=42 ensures same split every time (for reproducibility).\n","\n","Step 7: Train the Model\n","python\n","Copy\n","Edit\n","nb_classifier = GaussianNB()\n","nb_classifier.fit(X_train, y_train)\n","Create a Gaussian NaÃ¯ve Bayes object.\n","\n","Train (fit) it on training data.\n","\n","Step 8: Make Predictions\n","python\n","Copy\n","Edit\n","y_pred = nb_classifier.predict(X_test)\n","Predict the species on the test data.\n","\n","Step 9: Confusion Matrix\n","python\n","Copy\n","Edit\n","conf_matrix = confusion_matrix(y_test, y_pred, labels=y.unique())\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","Generate a confusion matrix comparing actual (y_test) vs predicted (y_pred).\n","\n","Print the confusion matrix.\n","\n","Step 10: Calculate TP, FP, TN, FN\n","python\n","Copy\n","Edit\n","tp = conf_matrix.diagonal()\n","fp = conf_matrix.sum(axis=0) - tp\n","fn = conf_matrix.sum(axis=1) - tp\n","tn = conf_matrix.sum() - (tp + fp + fn)\n","TP = Diagonal elements.\n","\n","FP = Column sums - TP.\n","\n","FN = Row sums - TP.\n","\n","TN = Total samples - (TP + FP + FN).\n","\n","Step 11: Calculate Metrics\n","python\n","Copy\n","Edit\n","accuracy = accuracy_score(y_test, y_pred)\n","error_rate = 1 - accuracy\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","Accuracy: How many total predictions were correct.\n","\n","Error Rate: How many were wrong.\n","\n","Precision: How many predicted positives are actually positive.\n","\n","Recall: How many actual positives are correctly predicted.\n","\n","Step 12: Print Results\n","python\n","Copy\n","Edit\n","print(\"\\nMetrics:\")\n","print(f\"True Positives (TP): {tp}\")\n","print(f\"False Positives (FP): {fp}\")\n","print(f\"True Negatives (TN): {tn}\")\n","print(f\"False Negatives (FN): {fn}\")\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(f\"Error Rate: {error_rate:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","Display all calculated values neatly.\n","\n","ğŸ¯ FINAL RESULT\n","By running this code:\n","\n","You trained a simple NaÃ¯ve Bayes model on Iris data.\n","\n","You evaluated the model using confusion matrix and computed:\n","\n","TP, FP, TN, FN, Accuracy, Error Rate, Precision, Recall."],"metadata":{"id":"CyCCMhL1rKbt"}}]}