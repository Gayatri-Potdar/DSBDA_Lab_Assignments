{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e74230",
   "metadata": {},
   "source": [
    "1) Data Wrangling, I\n",
    "Perform the following operations using Python on any open-source dataset (e.g., data.csv)\n",
    "1. Import all the required Python Libraries.\n",
    "2. Locate an open-source data from the web (e.g., https://www.kaggle.com). Provide a clear\n",
    "description of the data and its source (i.e., URL of the web site).\n",
    "3. Load the Dataset into pandas dataframe.\n",
    "4. Data Preprocessing: check for missing values in the data using pandas isnull (), describe ()\n",
    "function to get some initial statistics. Provide variable descriptions. Types of variables etc.\n",
    "Check the dimensions of the data frame.\n",
    "5. Data Formatting and Data Normalization: Summarize the types of variables by checking\n",
    "the data types (i.e., character, numeric, integer, factor, and logical) of the variables in the\n",
    "data set. If variables are not in the correct data type, apply proper type conversions.\n",
    "6. Turn categorical variables into quantitative variables in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8011a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322bf114",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']\n",
    "iris = pd.read_csv(csv_url, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05f0d12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows (head()):\n",
      "    Sepal_Length  Sepal_Width  Petal_Length  Petal_Width      Species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# Display first 5 rows\n",
    "print(\"First 5 Rows (head()):\\n\", iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeabf2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check Missing Values (isnull()):\n",
      "      Sepal_Length  Sepal_Width  Petal_Length  Petal_Width  Species\n",
      "0           False        False         False        False    False\n",
      "1           False        False         False        False    False\n",
      "2           False        False         False        False    False\n",
      "3           False        False         False        False    False\n",
      "4           False        False         False        False    False\n",
      "..            ...          ...           ...          ...      ...\n",
      "145         False        False         False        False    False\n",
      "146         False        False         False        False    False\n",
      "147         False        False         False        False    False\n",
      "148         False        False         False        False    False\n",
      "149         False        False         False        False    False\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Check Missing Values\n",
    "print(\"\\nCheck Missing Values (isnull()):\\n\", iris.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d10e692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Any Missing Values in Columns (isnull().any()):\n",
      " Sepal_Length    False\n",
      "Sepal_Width     False\n",
      "Petal_Length    False\n",
      "Petal_Width     False\n",
      "Species         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAny Missing Values in Columns (isnull().any()):\\n\", iris.isnull().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59846c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Missing Values (isnull().sum().sum()):\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Missing Values (isnull().sum().sum()):\\n\", iris.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01b4661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Describe the Dataset:\n",
      "        Sepal_Length  Sepal_Width  Petal_Length  Petal_Width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Describe the Dataset\n",
    "print(\"\\nDescribe the Dataset:\\n\", iris.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b034bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Index:\n",
      " RangeIndex(start=0, stop=150, step=1)\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Dataset Index\n",
    "print(\"\\nDataset Index:\\n\", iris.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d04e6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Columns:\n",
      " Index(['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width',\n",
      "       'Species'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.4 Dataset Columns\n",
    "print(\"\\nDataset Columns:\\n\", iris.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2267541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Shape (Rows, Columns):\n",
      " (150, 5)\n"
     ]
    }
   ],
   "source": [
    "# 3.5 Dataset Shape\n",
    "print(\"\\nDataset Shape (Rows, Columns):\\n\", iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb93f790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Data Types (dtypes):\n",
      " Sepal_Length    float64\n",
      "Sepal_Width     float64\n",
      "Petal_Length    float64\n",
      "Petal_Width     float64\n",
      "Species          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 3.6 Dataset Data Types\n",
    "print(\"\\nDataset Data Types (dtypes):\\n\", iris.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a3fc715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sepal_Length Column:\n",
      " 0      5.1\n",
      "1      4.9\n",
      "2      4.7\n",
      "3      4.6\n",
      "4      5.0\n",
      "      ... \n",
      "145    6.7\n",
      "146    6.3\n",
      "147    6.5\n",
      "148    6.2\n",
      "149    5.9\n",
      "Name: Sepal_Length, Length: 150, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3.7 Read Data Column-wise\n",
    "print(\"\\nSepal_Length Column:\\n\", iris['Sepal_Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecef24a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data at 5th Index (iloc[5]):\n",
      " Sepal_Length            5.4\n",
      "Sepal_Width             3.9\n",
      "Petal_Length            1.7\n",
      "Petal_Width             0.4\n",
      "Species         Iris-setosa\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 3.8 Read Specific Row by iloc\n",
    "print(\"\\nData at 5th Index (iloc[5]):\\n\", iris.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9369c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows 0 to 2 (iris[0:3]):\n",
      "    Sepal_Length  Sepal_Width  Petal_Length  Petal_Width      Species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# 3.9 Read Rows 0 to 2 (Slicing)\n",
    "print(\"\\nRows 0 to 2 (iris[0:3]):\\n\", iris[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f233e016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select Sepal_Length and Sepal_Width Columns:\n",
      "      Sepal_Length  Sepal_Width\n",
      "0             5.1          3.5\n",
      "1             4.9          3.0\n",
      "2             4.7          3.2\n",
      "3             4.6          3.1\n",
      "4             5.0          3.6\n",
      "..            ...          ...\n",
      "145           6.7          3.0\n",
      "146           6.3          2.5\n",
      "147           6.5          3.0\n",
      "148           6.2          3.4\n",
      "149           5.9          3.0\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.10 Select specific columns using loc\n",
    "print(\"\\nSelect Sepal_Length and Sepal_Width Columns:\\n\", iris.loc[:, [\"Sepal_Length\", \"Sepal_Width\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69116b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 Rows Subset (iloc[:5, :]):\n",
      "    Sepal_Length  Sepal_Width  Petal_Length  Petal_Width      Species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# 3.11 Subset first 5 rows (iloc)\n",
    "print(\"\\nFirst 5 Rows Subset (iloc[:5, :]):\\n\", iris.iloc[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37a2e166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 3 Columns Subset (iloc[:, :3]):\n",
      "      Sepal_Length  Sepal_Width  Petal_Length\n",
      "0             5.1          3.5           1.4\n",
      "1             4.9          3.0           1.4\n",
      "2             4.7          3.2           1.3\n",
      "3             4.6          3.1           1.5\n",
      "4             5.0          3.6           1.4\n",
      "..            ...          ...           ...\n",
      "145           6.7          3.0           5.2\n",
      "146           6.3          2.5           5.0\n",
      "147           6.5          3.0           5.2\n",
      "148           6.2          3.4           5.4\n",
      "149           5.9          3.0           5.1\n",
      "\n",
      "[150 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.12 Subset first 3 columns (iloc)\n",
    "print(\"\\nFirst 3 Columns Subset (iloc[:, :3]):\\n\", iris.iloc[:, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "590b9a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subset first 5 Rows and 3 Columns (iloc[:5, :3]):\n",
      "    Sepal_Length  Sepal_Width  Petal_Length\n",
      "0           5.1          3.5           1.4\n",
      "1           4.9          3.0           1.4\n",
      "2           4.7          3.2           1.3\n",
      "3           4.6          3.1           1.5\n",
      "4           5.0          3.6           1.4\n"
     ]
    }
   ],
   "source": [
    "# 3.13 Subset first 5 rows and first 3 columns (iloc)\n",
    "print(\"\\nSubset first 5 Rows and 3 Columns (iloc[:5, :3]):\\n\", iris.iloc[:5, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9be266f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types Before Formatting:\n",
      " Sepal_Length    float64\n",
      "Sepal_Width     float64\n",
      "Petal_Length    float64\n",
      "Petal_Width     float64\n",
      "Species          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# Step 4: Data Formatting and Normalization\n",
    "# -----------------------------------------------\n",
    "\n",
    "# 4.1 Check Data Types Again\n",
    "print(\"\\nData Types Before Formatting:\\n\", iris.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "339191cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 If Needed, Convert Data Types (example shown - not necessary here)\n",
    "iris['Sepal_Length'] = iris['Sepal_Length'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c116297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Normalize Numeric Data (Min-Max Scaling)\n",
    "numeric_columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5aa3fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Scaler\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fb99327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Normalization\n",
    "iris[numeric_columns] = min_max_scaler.fit_transform(iris[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "679b80b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized Data (0-1 Range):\n",
      "    Sepal_Length  Sepal_Width  Petal_Length  Petal_Width      Species\n",
      "0      0.333333     0.625000      0.067797     0.041667  Iris-setosa\n",
      "1      0.000000     0.416667      0.067797     0.041667  Iris-setosa\n",
      "2      0.000000     0.500000      0.050847     0.041667  Iris-setosa\n",
      "3      0.000000     0.458333      0.084746     0.041667  Iris-setosa\n",
      "4      0.333333     0.666667      0.067797     0.041667  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# View Normalized Data\n",
    "print(\"\\nNormalized Data (0-1 Range):\\n\", iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3f1f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# Step 5: Convert Categorical Variables to Quantitative\n",
    "# -----------------------------------------------\n",
    "\n",
    "# 5.1 Label Encode the 'Species' column\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "iris['Species'] = label_encoder.fit_transform(iris['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13bb731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Label Encoding Species:\n",
      "    Sepal_Length  Sepal_Width  Petal_Length  Petal_Width  Species\n",
      "0      0.333333     0.625000      0.067797     0.041667        0\n",
      "1      0.000000     0.416667      0.067797     0.041667        0\n",
      "2      0.000000     0.500000      0.050847     0.041667        0\n",
      "3      0.000000     0.458333      0.084746     0.041667        0\n",
      "4      0.333333     0.666667      0.067797     0.041667        0\n"
     ]
    }
   ],
   "source": [
    "# View After Label Encoding\n",
    "print(\"\\nAfter Label Encoding Species:\\n\", iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19de2682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Encoded Species Labels:\n",
      " [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Check Encoded Values\n",
    "print(\"\\nUnique Encoded Species Labels:\\n\", iris['Species'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b0286",
   "metadata": {},
   "source": [
    "📖 Theory: Functions Used in Data Wrangling Practical\n",
    "1. pd.read_csv()\n",
    "Purpose and Explanation:\n",
    "pd.read_csv() is a function from the pandas library used to load a dataset stored in a CSV (Comma Separated Values) file format into a pandas DataFrame. It parses the file, identifies the fields, and structures the data into a tabular format. In our practical, we used pd.read_csv() to load the Iris dataset from the UCI Machine Learning Repository. Since the dataset did not have headers, we assigned the column names manually.\n",
    "\n",
    "Example:\n",
    "We loaded the data using:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris = pd.read_csv(csv_url, names=col_names)\n",
    "Importance:\n",
    "Reading structured data into DataFrames is the very first and most crucial step in any data science project, as all further operations depend on correctly loaded data.\n",
    "\n",
    "2. head()\n",
    "Purpose and Explanation:\n",
    "The head() function displays the first few records (default 5 rows) of the DataFrame. It helps in quick verification of whether the data has been loaded properly and the columns have been correctly assigned.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.head()\n",
    "Importance:\n",
    "This function is helpful for initial exploratory data analysis to observe the structure of the dataset.\n",
    "\n",
    "3. isnull()\n",
    "Purpose and Explanation:\n",
    "The isnull() function is used to identify missing values in a DataFrame. It returns a Boolean DataFrame indicating True where the data is missing.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.isnull()\n",
    "Importance:\n",
    "Detecting missing values early is important because they can affect model performance and lead to incorrect analysis if not handled properly.\n",
    "\n",
    "4. isnull().any()\n",
    "Purpose and Explanation:\n",
    "isnull().any() checks each column individually and returns True if any missing values are present in that column. It is a quicker way to detect missing data across columns.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.isnull().any()\n",
    "Importance:\n",
    "This is useful for summarizing which columns need cleaning before proceeding further.\n",
    "\n",
    "5. isnull().sum().sum()\n",
    "Purpose and Explanation:\n",
    "isnull().sum().sum() computes the total number of missing values across the entire DataFrame. First, it sums missing values per column and then aggregates them.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.isnull().sum().sum()\n",
    "Importance:\n",
    "It gives a complete picture of how much data is missing in the dataset.\n",
    "\n",
    "6. describe()\n",
    "Purpose and Explanation:\n",
    "The describe() function provides descriptive statistics like mean, standard deviation, min, max, and quartiles for numeric columns. It helps to quickly understand the distribution and spread of the data.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.describe()\n",
    "Importance:\n",
    "Descriptive statistics are important for understanding data variability and detecting outliers.\n",
    "\n",
    "7. index\n",
    "Purpose and Explanation:\n",
    "The index attribute shows the range of row labels in the DataFrame. It tells how many entries are present and the starting and ending points of the DataFrame.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.index\n",
    "Importance:\n",
    "Understanding indexing is crucial for operations like slicing and selecting data.\n",
    "\n",
    "8. columns\n",
    "Purpose and Explanation:\n",
    "The columns attribute lists all the column names of the DataFrame. It helps to verify if the data has correct feature labels.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.columns\n",
    "Importance:\n",
    "Knowing column names is important for referencing, selecting, and analyzing specific features.\n",
    "\n",
    "9. shape\n",
    "Purpose and Explanation:\n",
    "The shape attribute returns a tuple representing the dimensions of the DataFrame as (rows, columns).\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.shape\n",
    "Importance:\n",
    "It is important for understanding the size of the dataset and planning preprocessing steps accordingly.\n",
    "\n",
    "10. dtypes\n",
    "Purpose and Explanation:\n",
    "The dtypes attribute displays the datatype of each column, such as float64, int64, or object. Knowing the datatype is crucial for choosing the right data transformations.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.dtypes\n",
    "Importance:\n",
    "It helps ensure that the data types align with the kind of operations we plan to perform.\n",
    "\n",
    "11. iloc[]\n",
    "Purpose and Explanation:\n",
    "iloc[] stands for integer-location based indexing. It allows selection by row and column index positions, making it useful for slicing the DataFrame based on numerical indices.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.iloc[5]\n",
    "Importance:\n",
    "Essential for selecting data when the exact row/column labels are not known.\n",
    "\n",
    "12. loc[]\n",
    "Purpose and Explanation:\n",
    "loc[] allows label-based indexing. It is used for selecting subsets of data based on column names and row indices explicitly.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris.loc[:, ['Sepal_Length', 'Sepal_Width']]\n",
    "Importance:\n",
    "Useful when we want to select data based on actual labels rather than numeric indices.\n",
    "\n",
    "13. astype()\n",
    "Purpose and Explanation:\n",
    "The astype() function is used to change the datatype of a column. For example, converting a column from float64 to int64.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "iris['Sepal_Length'] = iris['Sepal_Length'].astype('float')\n",
    "Importance:\n",
    "Helps correct datatype issues that could affect data analysis and model training.\n",
    "\n",
    "14. preprocessing.MinMaxScaler()\n",
    "Purpose and Explanation:\n",
    "MinMaxScaler() from the sklearn library normalizes feature values to a standard range between 0 and 1. It is very important for algorithms that are sensitive to the scale of data.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "Importance:\n",
    "Ensures that no feature dominates others due to larger magnitude and speeds up model convergence.\n",
    "\n",
    "15. LabelEncoder()\n",
    "Purpose and Explanation:\n",
    "LabelEncoder() transforms categorical values (strings) into numerical values (integers). It is necessary because machine learning models work with numerical input.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "iris['Species'] = label_encoder.fit_transform(iris['Species'])\n",
    "Importance:\n",
    "Converting string labels to numerical form enables the use of categorical data in supervised learning models.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
